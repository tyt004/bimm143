---
title: "class09"
author: "Tiffany"
date: "10/29/2019"
output: html_document
---

```{r}
# Complete the following code to input the data and store as wisc.df
wisc.df <- read.csv("WisconsinCancer.csv")
head(wisc.df)
```

Not that the`id` and and `dianogsis` columns will not be used formost of the following steps

We have `r nrow(wisc.df)` samples in this database

```{r}
nrow(wisc.df)
```

How many benign (not cancerous) and malignant (cancerous) samples do we have
```{r}
table(wisc.df$diagnosis) #table(select data$ specify column)
```

# Convert the features of the data: wisc.data
```{r}
wisc.data <- as.matrix( wisc.df[,3:32] )

# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id

#head(wisc.data)
head(wisc.data)
```

Store the diagnosis for reference in the future as a separate vector
```{r}
dianogsis<-wisc.df$diagnosis
```


Q1. How many observations are in this dataset?
```{r}
nrow(wisc.data)
```

Q2. How many of the observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
```

Q3. How many variables/features in the data are suffixed with _mean?
```{r}
grep("_mean", colnames(wisc.df))# returns the position

```

```{r}
grep("_mean", colnames(wisc.df), value = TRUE)
```

#by using the length function you get the number of the "means" from the grep function
```{r}
length(grep("_mean", colnames(wisc.df)))
```


2.Principle Component Analysis 
#Performing PCA
The next step in your analysis is to perform principal component analysis (PCA) on wisc.data.

It is important to check if the data need to be scaled before performing PCA. Recall two common reasons for scaling data include:

The input variables use different units of measurement.
The input variables have significantly different variances.
Check the mean and standard deviation of the features (i.e. columns) of the wisc.data to determine if the data should be scaled. Use the colMeans() and apply() functions like you’ve done before.


```{r}
# Check column means and standard deviations
round(colMeans(wisc.data), 3) # the round fucntion arounf the colmeans rounds the answers to 3 sigfigs as signify by the  ",3)" at the end

```

```{r}
round(apply(wisc.data,2,sd), 3)
```
These values look very different so I will use `scale=TRUE` when I run the PCA

```{r}
# Perform PCA on wisc.data by completing the following code
wisc.pr <- prcomp(wisc.data, scale=TRUE)

# Look at summary of results
summary(wisc.pr)
```
# Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
the `Proportion of Variance` is how much the data capture the original variance. For PC1 it capture 44% of  the variance. PC2=19% etc.
```{r}
x<-summary(wisc.pr)
x$importance["PC1"]
#x$importance[,1]
```


#Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
3 PC

```{r}

x$importance[3,]> 0.7

```


#Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
```{r}
which(x$importance[3,]> 0.9) [1]
```






```{r}
plot(wisc.pr)
```


Lets make a plot of PC1 vs PC2
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2] )
```

Color by cancer/ non-cancer...
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=dianogsis)
```



```{r}
## ggplot based graph
#install.packages("factoextra")
#to instal go to tools and type in the name of the package and press install
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```


3. Hierarchical clustering
Hierarchical clustering of case data
The goal of this section is to do hierarchical clustering of the observations. Recall from our last class that this type of clustering does not assume in advance the number of natural groups that exist in the data.

As part of the preparation for hierarchical clustering, the distance between all pairs of observations are computed. Furthermore, there are different ways to link clusters together, with single, complete, and average being the most common linkage methods.

Scale the wisc.data data and assign the result to data.scaled.

```{r}
# Scale the wisc.data data: data.scaled
data.scaled <- scale(wisc.data)
```

Calculate the (Euclidean) distances between all pairs of observations in the new scaled dataset and assign the result to data.dist.
```{r}
data.dist <- dist(data.scaled)
```


```{r}
wisc.hclust <- hclust(data.dist, method = "complete", members = NULL)
```

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```



Clustering on PCA results
In this final section, you will put together several steps you used earlier and, in doing so, you will experience some of the creativity and open endedness that is typical in unsupervised learning.

Recall from earlier sections that the PCA model required significantly fewer features to describe 70%, 80% and 95% of the variability of the data. In addition to normalizing data and potentially avoiding over-fitting, PCA also uncorrelates the variables, sometimes improving the performance of other modeling techniques.

Let’s see if PCA improves or degrades the performance of hierarchical clustering.

Using the minimum number of principal components required to describe at least 90% of the variability in the data, create a hierarchical clustering model with the linkage method="ward.D2". We use Ward’s criterion here because it is based on multidimensional variance like principal components analysis. Assign the results to wisc.pr.hclust.

```{r}
hclust(dist(dist(wisc.pr$x[,1:3])))
```




First the original data
```{r}

```

Let's see the if the PCA improves or 
```{r}
wisc.pr.hclust<-hclust(dist(wisc.pr))
```





7. Prediction
We will use the predict() function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space.



```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```




```{r}
plot(wisc.pr$x[,1:2], col=dianogsis)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], label=c(1,2), col="white")
```



Q17. Which of these new patients should we prioritize for follow up based on your results?
-we should prioritize patient 2 for treatment
















